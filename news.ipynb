{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install newscatcherapi-python-sdk==6.0.2 -q\n",
    "%pip install langchain==0.1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from newscatcherapi_client import Newscatcher, ApiException\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import botocore\n",
    "import boto3\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "import re\n",
    "\n",
    "\n",
    "def llm_news_generator():\n",
    "\n",
    "    newscatcher = Newscatcher(\n",
    "        api_key=\"INSERT API KEY\",\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_response = newscatcher.search.get(\n",
    "            q=\"flu\",\n",
    "            search_in=\"title_content\",\n",
    "            clustering_enabled=True,\n",
    "            from_='7 day ago',\n",
    "        )\n",
    "    except ApiException as e:\n",
    "        print(\"Exception when calling AuthorsApi.get: %s\\n\" % e)\n",
    "        if e.status == 422:\n",
    "            pprint(e.body[\"detail\"])\n",
    "        pprint(e.headers)\n",
    "        pprint(e.status)\n",
    "        pprint(e.reason)\n",
    "        pprint(e.round_trip_time)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    def remove_duplicates(s):\n",
    "        return ' '.join(sorted(set(s.split())))\n",
    "\n",
    "    for j in range(len(get_response.clusters)):\n",
    "        \n",
    "        test_data = get_response.clusters[j]\n",
    "\n",
    "        all_cluster_text = \"\"\n",
    "        country = \"\"\n",
    "\n",
    "        for i in range(len(test_data.articles)):\n",
    "\n",
    "            description = test_data.articles[i]['description']\n",
    "            if description is not None:\n",
    "                all_cluster_text += description\n",
    "            else:\n",
    "                all_cluster_text += test_data.articles[i]['title']\n",
    "\n",
    "            country_link =  test_data.articles[i]['country']\n",
    "            if country_link is not None:\n",
    "                country += \" \" + country_link\n",
    "            else:\n",
    "                country += ' None'\n",
    "\n",
    "        country = remove_duplicates(country.strip())\n",
    "\n",
    "        # Append to data list\n",
    "        data.append({'Country': country.strip(), 'ClusterText': all_cluster_text.strip()})\n",
    "\n",
    "    # Create a DataFrame from the data list\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Bedrock\n",
    "    boto3_bedrock = boto3.client('bedrock')\n",
    "    bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "\n",
    "    prompt = \"\"\"\n",
    "\n",
    "    Human: Given the description of illness/diseases provided , please read it and analyse the contents.\n",
    "\n",
    "    Please extract the following information from the email:\n",
    "    - Whether the Illness or diseases is an outbreak or not, return it inside <outbreak></outbreak> XML tags usinfg TRUE or FALSE, TRUE is it is an outbreak, FALSE if it is not. Return Unsure, of not sure.\n",
    "    - TThe number of cases reported from the description in HUMANS <cases></cases> XML tags as a number.\n",
    "    - The name of the illness from the description <name></name> XML tags.\n",
    "    - The sentiment on whether the article is negative or neutral <sentiment></sentiment> XML tags.\n",
    "    - The regions where the incident occured, by states/cities <region></region> XML tags.\n",
    "    - TThe number of deaths reported from the description in HUMANS <deaths></deaths> XML tags as a number.\n",
    "    - The description of the disease/illness in english <description></description> XML tags.\n",
    "\n",
    "\n",
    "    If a particular bit of information is not present, return an empty string.\n",
    "    Make sure that each question can be understoon by itself, incorporate context if requred.\n",
    "    Each returned question should be concise, remove extra information if possible.\n",
    "    The dontext will be given between <context></context> XML tags.\n",
    "\n",
    "    <context>\n",
    "    {data_test}\n",
    "    </context>\n",
    "\n",
    "    Return the outbreak inside <outbreak></outbreak> XML tags.\n",
    "    Return the number of cases in HUMANS inside <cases></cases> XML tags.\n",
    "    Return the name of the illness or diseases inside <name></name> XML tags.\n",
    "    Return the sentiment of the context inside <sentiment></sentiment> XML tags.\n",
    "    Return the name of the region inside <region></region> XML tags.\n",
    "    Return the number of deaths in HUMANS inside <deaths></deaths> XML tags.\n",
    "    Return the description of the context inside <description></description> XML tags.\n",
    "\n",
    "\n",
    "    Assistant:\"\"\"\n",
    "\n",
    "    df = df[df['ClusterText']!=\"\"].reset_index(drop=True)\n",
    "\n",
    "    data_llm = []\n",
    "\n",
    "    # - create the Anthropic Model\n",
    "    llm = Bedrock(\n",
    "        model_id=\"anthropic.claude-v2\",\n",
    "        client=bedrock_runtime,\n",
    "        model_kwargs={\n",
    "            \"max_tokens_to_sample\": 2000,\n",
    "            \"temperature\": 0, # Using 0 to get reproducible results\n",
    "            \"stop_sequences\": [\"\\n\\nHuman:\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for i in range(len(df)):    \n",
    "        query = prompt.format(data_test=df['ClusterText'][i])\n",
    "        result = llm(query).strip()\n",
    "        \n",
    "\n",
    "        # Define regular expressions to extract data\n",
    "        patterns = {\n",
    "            'outbreak': r'<outbreak>(.*?)</outbreak>',\n",
    "            'cases': r'<cases>(.*?)</cases>',\n",
    "            'name': r'<name>(.*?)</name>',\n",
    "            'sentiment': r'<sentiment>(.*?)</sentiment>',\n",
    "            'region': r'<region>(.*?)</region>',\n",
    "            'description': r'<description>(.*?)</description>',\n",
    "            'deaths': r'<deaths>(.*?)</deaths>'\n",
    "        }\n",
    "\n",
    "        # Extract data using regular expressions\n",
    "        data_dict = {key: re.findall(pattern, result, re.DOTALL)[0] for key, pattern in patterns.items()}\n",
    "\n",
    "        # Create a DataFrame from the dictionary\n",
    "        df1 = pd.DataFrame([data_dict])\n",
    "\n",
    "        data_llm.append(data_dict)\n",
    "\n",
    "    df1 = pd.DataFrame(data_llm)\n",
    "\n",
    "    #df1 = pd.DataFrame(data_llm)\n",
    "    df_final = pd.concat([df,df1], axis=1)\n",
    "\n",
    "    return(df_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Flu Outbreaks\n",
    "output = llm_news_generator()\n",
    "output.to_csv('news_output.csv')\n",
    "outbreaks = output[output['outbreak']=='TRUE']\n",
    "outbreaks = outbreaks.drop_duplicates(subset='name').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity extraction, sentiment analysis etr on outbreaks\n",
    "df_outbreak_final = pd.DataFrame()\n",
    "for j in range(len(outbreaks)):\n",
    "\n",
    "    newscatcher = Newscatcher(\n",
    "            api_key=\"INSERT API KEY\",\n",
    "        )\n",
    "    try:\n",
    "        # [Get] Search By Author Request\n",
    "        get_response = newscatcher.search.get(\n",
    "            q=outbreaks.name[j],\n",
    "            search_in=\"title_content\",\n",
    "            #clustering_enabled=True,\n",
    "            from_='14 day ago',\n",
    "        )\n",
    "        #print(get_response)\n",
    "    except ApiException as e:\n",
    "        print(\"Exception when calling AuthorsApi.get: %s\\n\" % e)\n",
    "        #pprint(e.body)\n",
    "        if e.status == 422:\n",
    "            pprint(e.body[\"detail\"])\n",
    "        pprint(e.headers)\n",
    "        pprint(e.status)\n",
    "        pprint(e.reason)\n",
    "        pprint(e.round_trip_time)\n",
    "\n",
    "        prompt_detail = \"\"\"\n",
    "\n",
    "        Human: Given the description of illness/diseases provided, please read it and analyse the contents.\n",
    "\n",
    "        Please extract the following information from the email:\n",
    "        - TThe number of cases reported from the description in HUMANS <cases></cases> XML tags as a number.\n",
    "        - The sentiment on whether the article is positive, negative or neutral <sentiment></sentiment> XML tags.\n",
    "        - The regions where the incident occured, by states/cities <region></region> XML tags.\n",
    "        - TThe number of deaths reported from the description in HUMANS <deaths></deaths> XML tags as a number.\n",
    "        - The description of the disease/illness in english <description></description> XML tags.\n",
    "        - A very brief description of the impacts caused by the disease such as closures, bans or similar items <impacts></impacts> XML tags.\n",
    "        - A very brief description of the impact on business caused by the disease <impacts_business></impacts_business> XML tags.\n",
    "\n",
    "\n",
    "        If a particular bit of information is not present, return an empty string.\n",
    "        Make sure that each question can be understoon by itself, incorporate context if requred.\n",
    "        Each returned question should be concise, remove extra information if possible.\n",
    "        The dontext will be given between <context></context> XML tags.\n",
    "\n",
    "        <context>\n",
    "        {data_test}\n",
    "        </context>\n",
    "\n",
    "        Return the number of cases in HUMANS inside <cases></cases> XML tags.\n",
    "        Return the sentiment of the context inside <sentiment></sentiment> XML tags.\n",
    "        Return the name of the region inside <region></region> XML tags.\n",
    "        Return the number of deaths in HUMANS inside <deaths></deaths> XML tags.\n",
    "        Return the description of the context inside <description></description> XML tags.\n",
    "        Return the impacts of the disease/illness inside <impacts></impacts> XML tags.\n",
    "        Return the impact on trade/infrastructure/business caused by the disease inside <impacts_business></impacts_business> XML tags.\n",
    "\n",
    "        Assistant:\"\"\"\n",
    "\n",
    "        outbreak_1 = pd.DataFrame(get_response.articles)\n",
    "        \n",
    "        boto3_bedrock = boto3.client('bedrock')\n",
    "        bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "        # - create the Anthropic Model\n",
    "        llm = Bedrock(\n",
    "            model_id=\"anthropic.claude-v2\",\n",
    "            client=bedrock_runtime,\n",
    "            model_kwargs={\n",
    "                #\"max_tokens_to_sample\": 200000,\n",
    "                \"temperature\": 0, # Using 0 to get reproducible results\n",
    "                \"stop_sequences\": [\"\\n\\nHuman:\"]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        data_llm_oubreak = []\n",
    "\n",
    "        for i in range(len(outbreak_1)):    \n",
    "            \n",
    "            query = prompt_detail.format(data_test=outbreak_1['content'][i])\n",
    "            result = llm(query).strip()\n",
    "            \n",
    "\n",
    "            # Define regular expressions to extract data\n",
    "            patterns = {\n",
    "                'cases': r'<cases>(.*?)</cases>',\n",
    "                'sentiment': r'<sentiment>(.*?)</sentiment>',\n",
    "                'region': r'<region>(.*?)</region>',\n",
    "                'description': r'<description>(.*?)</description>',\n",
    "                'deaths': r'<deaths>(.*?)</deaths>',\n",
    "                'impacts': r'<impacts>(.*?)</impacts>',\n",
    "                'impacts_business': r'<impacts_business>(.*?)</impacts_business>'\n",
    "\n",
    "            }\n",
    "\n",
    "            data_dict = {}\n",
    "\n",
    "            # Extract data using regular expressions\n",
    "            for key, pattern in patterns.items():\n",
    "                match = re.findall(pattern, result, re.DOTALL)\n",
    "                if match:\n",
    "                    data_dict[key] = match[0]\n",
    "                else:\n",
    "                    data_dict[key] = None\n",
    "\n",
    "            # Create a DataFrame from the dictionary\n",
    "            df2 = pd.DataFrame([data_dict])\n",
    "\n",
    "            data_llm_oubreak.append(data_dict)\n",
    "\n",
    "        df2 = pd.DataFrame(data_llm_oubreak)\n",
    "        \n",
    "        df4 = pd.DataFrame(data_llm_oubreak)\n",
    "\n",
    "        df_outbreak1 = pd.concat([outbreak_1,df4], axis=1)\n",
    "\n",
    "        df_outbreak1 = df_outbreak1.dropna(subset='sentiment')\n",
    "\n",
    "        impacts = df_outbreak1['impacts'][0]\n",
    "        impacts_business = df_outbreak1[df_outbreak1['impacts_business']!=''].reset_index()['impacts_business'][0]\n",
    "        top_article = df_outbreak1['title'][0]\n",
    "        negative_sentiment = round(len(df_outbreak1[df_outbreak1['sentiment'].str.lower() == 'negative'])/len(df_outbreak1),2)*100\n",
    "        outbreak_name = outbreaks.name[j]\n",
    "\n",
    "        df_outbreak_final_dict = {'outbreak_name': [outbreak_name],'impacts': [impacts], 'impacts_business': [impacts_business], 'top_article': [top_article], 'negative_sentiment': [negative_sentiment]}\n",
    "\n",
    "    outbreak_output = pd.concat([df_outbreak_final, pd.DataFrame(df_outbreak_final_dict)], ignore_index=True)\n",
    "    #Save\n",
    "    outbreak_output.to_csv('llm_news_detail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute similarity between descriptions\n",
    "def compute_similarity(desc1, desc2):\n",
    "    return fuzz.ratio(desc1.lower(), desc2.lower())\n",
    "\n",
    "# Grouping descriptions based on similarity\n",
    "grouped_descriptions = {}\n",
    "\n",
    "for desc1 in df_outbreak1['description']:\n",
    "    found_group = False\n",
    "    for group in grouped_descriptions:\n",
    "        for desc2 in group:\n",
    "            if compute_similarity(desc1, desc2) > 80:  # You can adjust this threshold\n",
    "                grouped_descriptions[group].append(desc1)\n",
    "                found_group = True\n",
    "                break\n",
    "        if found_group:\n",
    "            break\n",
    "    if not found_group:\n",
    "        grouped_descriptions[tuple([desc1])] = [desc1]\n",
    "\n",
    "# Create a DataFrame from grouped descriptions\n",
    "grouped_data = pd.DataFrame([(desc_group[0], ', '.join(desc_group), len(desc_group)) for desc_group in grouped_descriptions.values()], columns=['representative_description', 'grouped_descriptions', 'count'])\n",
    "\n",
    "# Calculate the percentage of negative sentiments for each group\n",
    "negative_percentages = []\n",
    "\n",
    "for group in grouped_data['grouped_descriptions']:\n",
    "    sentiments = [df_outbreak1.loc[df_outbreak1['description'] == desc, 'sentiment'].iloc[0] for desc in group.split(', ')]\n",
    "    negative_count = sentiments.count('negative')\n",
    "    total_count = len(sentiments)\n",
    "    negative_percentage = (negative_count / total_count) * 100\n",
    "    negative_percentages.append(negative_percentage)\n",
    "\n",
    "grouped_data['negative_percentage'] = negative_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>representative_description</th>\n",
       "      <th>grouped_descriptions</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>description</td>\n",
       "      <td>description, description</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  representative_description      grouped_descriptions  count\n",
       "0                description  description, description      2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_outbreak1 = df_outbreak1[['cases', 'sentiment', 'region', 'description', 'deaths', 'impact','impact_business', 'published_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cases</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>region</th>\n",
       "      <th>description</th>\n",
       "      <th>description</th>\n",
       "      <th>deaths</th>\n",
       "      <th>impact</th>\n",
       "      <th>impact_business</th>\n",
       "      <th>published_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>945</td>\n",
       "      <td>negative</td>\n",
       "      <td>Rajasthan, Udaipur, Jaipur, Bikaner, Bhilwara,...</td>\n",
       "      <td>Among the 12 swine flu deaths, four cases were...</td>\n",
       "      <td>Swine flu outbreak in Rajasthan, India with 94...</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-15 13:49:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>Nashik, India</td>\n",
       "      <td>The sudden rise in swine flu cases has sparked...</td>\n",
       "      <td>The article describes a concerning rise in swi...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-16 10:37:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>945</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>Despite the significant rise in swine flu case...</td>\n",
       "      <td>The email describes an outbreak of swine flu i...</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-14 07:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>945</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Rajasthan, Jaipur, Udaipur, Bhilwara, Bikaner,...</td>\n",
       "      <td>Swine flu caused fatalities in Rajasthan. Jaip...</td>\n",
       "      <td>The article describes an outbreak of swine flu...</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-14 04:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>United States</td>\n",
       "      <td>U.S. swine herd has not been implicated in the...</td>\n",
       "      <td>The article discusses emerging and reemerging ...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-11 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>Nashik, Maharashtra</td>\n",
       "      <td>Nashik News : स्वाईन फ्ल्यूचा प्रादुर्भाव जवळप...</td>\n",
       "      <td>The article describes cases of swine flu and C...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-16 05:08:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39-56 million</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>North America, Europe, Asia, Rest of World (ROW)</td>\n",
       "      <td>/PRNewswire/ -- The global influenza vaccine m...</td>\n",
       "      <td>The article discusses the global influenza vac...</td>\n",
       "      <td>400,000-730,000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-16 14:24:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No cases mentioned</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Kabupaten Sikka, Nusa Tenggara Timur</td>\n",
       "      <td>Pemkab Sikka, NTT telusuri laporan ternak babi...</td>\n",
       "      <td>The local government in Sikka Regency, East Nu...</td>\n",
       "      <td>No deaths mentioned</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-15 10:00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No cases mentioned</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Minnesota, Texas, Michigan, Kansas, New Mexico...</td>\n",
       "      <td>But the rash of recent infections among livest...</td>\n",
       "      <td>The article discusses an outbreak of avian inf...</td>\n",
       "      <td>No deaths mentioned</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-05 21:34:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Negative</td>\n",
       "      <td>United States, Texas, Antarctica, Vietnam, Chile</td>\n",
       "      <td>This Flu Focus includes the challenges of avia...</td>\n",
       "      <td>The email discusses outbreaks of avian influen...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-11 16:45:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>No cases mentioned</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>India</td>\n",
       "      <td>In 2001, H5N1 virus was expected to cause the ...</td>\n",
       "      <td>The article discusses avian influenza or bird ...</td>\n",
       "      <td>No deaths mentioned</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-09 09:32:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>By Niamh Harris – The People's Voice The World...</td>\n",
       "      <td>The article discusses the lack of a clear defi...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-16 13:55:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Nashik, Maharashtra</td>\n",
       "      <td>नाशिक : गेल्या वर्षातील नाशिक शहरावरील डेंग्यू...</td>\n",
       "      <td>\\nThe article describes an outbreak of swine f...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-16 05:18:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>No cases mentioned</td>\n",
       "      <td>Negative</td>\n",
       "      <td>No specific region mentioned</td>\n",
       "      <td>There is no universally agreed definition of '...</td>\n",
       "      <td>The article discusses the lack of a clear defi...</td>\n",
       "      <td>No deaths mentioned</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-16 11:18:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>Maharashtra, Nasik</td>\n",
       "      <td>Swine Flu in Nashik: नासिक में स्वाइन फ्लू के ...</td>\n",
       "      <td>The article describes cases of swine flu (H1N1...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-16 09:06:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>The bird flu outbreak has now affected dairy c...</td>\n",
       "      <td>The article describes an outbreak of avian inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-10 12:47:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29 dairy herds</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Michigan, Idaho, North Carolina, Texas, New Me...</td>\n",
       "      <td>Michigan officials said the H5N1 bird flu viru...</td>\n",
       "      <td>The H5N1 bird flu virus has infected three add...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-15 13:16:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>The Ministry of Agriculture, Livestock and Foo...</td>\n",
       "      <td>The Ministry of Agriculture in Guatemala is ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-10 10:00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>Also updated PDF compilations</td>\n",
       "      <td>The email provides background information and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-09 20:00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>The porcine vaccine market size has grown stro...</td>\n",
       "      <td>The article provides an overview and analysis ...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-04-11 05:59:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cases sentiment  \\\n",
       "0                  945  negative   \n",
       "1                    3  negative   \n",
       "2                  945  Negative   \n",
       "3                  945  Negative   \n",
       "4                    0   neutral   \n",
       "5                    3  negative   \n",
       "6        39-56 million   Neutral   \n",
       "7   No cases mentioned  Negative   \n",
       "8   No cases mentioned  Negative   \n",
       "9              Unknown  Negative   \n",
       "10  No cases mentioned   Neutral   \n",
       "11                   0   neutral   \n",
       "12                   3  Negative   \n",
       "13  No cases mentioned  Negative   \n",
       "14                   3  negative   \n",
       "15                   1  negative   \n",
       "16      29 dairy herds  Negative   \n",
       "17                   0   neutral   \n",
       "18                   0   neutral   \n",
       "19                   0   neutral   \n",
       "\n",
       "                                               region  \\\n",
       "0   Rajasthan, Udaipur, Jaipur, Bikaner, Bhilwara,...   \n",
       "1                                       Nashik, India   \n",
       "2                                           Rajasthan   \n",
       "3   Rajasthan, Jaipur, Udaipur, Bhilwara, Bikaner,...   \n",
       "4                                       United States   \n",
       "5                                 Nashik, Maharashtra   \n",
       "6    North America, Europe, Asia, Rest of World (ROW)   \n",
       "7                Kabupaten Sikka, Nusa Tenggara Timur   \n",
       "8   Minnesota, Texas, Michigan, Kansas, New Mexico...   \n",
       "9    United States, Texas, Antarctica, Vietnam, Chile   \n",
       "10                                              India   \n",
       "11                                                      \n",
       "12                                Nashik, Maharashtra   \n",
       "13                       No specific region mentioned   \n",
       "14                                 Maharashtra, Nasik   \n",
       "15                                              Texas   \n",
       "16  Michigan, Idaho, North Carolina, Texas, New Me...   \n",
       "17                                          Guatemala   \n",
       "18                                                      \n",
       "19                                                      \n",
       "\n",
       "                                          description  \\\n",
       "0   Among the 12 swine flu deaths, four cases were...   \n",
       "1   The sudden rise in swine flu cases has sparked...   \n",
       "2   Despite the significant rise in swine flu case...   \n",
       "3   Swine flu caused fatalities in Rajasthan. Jaip...   \n",
       "4   U.S. swine herd has not been implicated in the...   \n",
       "5   Nashik News : स्वाईन फ्ल्यूचा प्रादुर्भाव जवळप...   \n",
       "6   /PRNewswire/ -- The global influenza vaccine m...   \n",
       "7   Pemkab Sikka, NTT telusuri laporan ternak babi...   \n",
       "8   But the rash of recent infections among livest...   \n",
       "9   This Flu Focus includes the challenges of avia...   \n",
       "10  In 2001, H5N1 virus was expected to cause the ...   \n",
       "11  By Niamh Harris – The People's Voice The World...   \n",
       "12  नाशिक : गेल्या वर्षातील नाशिक शहरावरील डेंग्यू...   \n",
       "13  There is no universally agreed definition of '...   \n",
       "14  Swine Flu in Nashik: नासिक में स्वाइन फ्लू के ...   \n",
       "15  The bird flu outbreak has now affected dairy c...   \n",
       "16  Michigan officials said the H5N1 bird flu viru...   \n",
       "17  The Ministry of Agriculture, Livestock and Foo...   \n",
       "18                      Also updated PDF compilations   \n",
       "19  The porcine vaccine market size has grown stro...   \n",
       "\n",
       "                                          description               deaths  \\\n",
       "0   Swine flu outbreak in Rajasthan, India with 94...                   12   \n",
       "1   The article describes a concerning rise in swi...                    1   \n",
       "2   The email describes an outbreak of swine flu i...                   12   \n",
       "3   The article describes an outbreak of swine flu...                   12   \n",
       "4   The article discusses emerging and reemerging ...                    0   \n",
       "5   The article describes cases of swine flu and C...                    1   \n",
       "6   The article discusses the global influenza vac...      400,000-730,000   \n",
       "7   The local government in Sikka Regency, East Nu...  No deaths mentioned   \n",
       "8   The article discusses an outbreak of avian inf...  No deaths mentioned   \n",
       "9   The email discusses outbreaks of avian influen...              Unknown   \n",
       "10  The article discusses avian influenza or bird ...  No deaths mentioned   \n",
       "11  The article discusses the lack of a clear defi...                    0   \n",
       "12  \\nThe article describes an outbreak of swine f...                    1   \n",
       "13  The article discusses the lack of a clear defi...  No deaths mentioned   \n",
       "14  The article describes cases of swine flu (H1N1...                    1   \n",
       "15  The article describes an outbreak of avian inf...                    1   \n",
       "16  The H5N1 bird flu virus has infected three add...                        \n",
       "17  The Ministry of Agriculture in Guatemala is ho...                    0   \n",
       "18  The email provides background information and ...                    0   \n",
       "19  The article provides an overview and analysis ...                    0   \n",
       "\n",
       "   impact impact_business       published_date  \n",
       "0    None            None  2024-04-15 13:49:20  \n",
       "1    None            None  2024-04-16 10:37:12  \n",
       "2    None            None  2024-04-14 07:03:00  \n",
       "3    None            None  2024-04-14 04:01:00  \n",
       "4    None            None  2024-04-11 05:00:00  \n",
       "5    None            None  2024-04-16 05:08:45  \n",
       "6    None            None  2024-04-16 14:24:00  \n",
       "7    None            None  2024-04-15 10:00:53  \n",
       "8    None            None  2024-04-05 21:34:37  \n",
       "9    None            None  2024-04-11 16:45:36  \n",
       "10   None            None  2024-04-09 09:32:33  \n",
       "11   None            None  2024-04-16 13:55:37  \n",
       "12   None            None  2024-04-16 05:18:06  \n",
       "13   None            None  2024-04-16 11:18:50  \n",
       "14   None            None  2024-04-16 09:06:17  \n",
       "15   None            None  2024-04-10 12:47:58  \n",
       "16   None            None  2024-04-15 13:16:24  \n",
       "17   None            None  2024-04-10 10:00:16  \n",
       "18   None            None  2024-04-09 20:00:23  \n",
       "19   None            None  2024-04-11 05:59:01  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_outbreak1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install boto3==1.33.2 --force-reinstall --quiet\n",
    "%pip install botocore==1.33.2 --force-reinstall --quiet\n",
    "%pip install -U opensearch-py==2.3.1\n",
    "%pip install -U boto3==1.33.2\n",
    "%pip install -U retrying==1.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import pprint\n",
    "from utility import create_bedrock_execution_role, create_oss_policy_attach_bedrock_execution_role, create_policies_in_oss, interactive_sleep\n",
    "import random\n",
    "from retrying import retry\n",
    "suffix = random.randrange(200, 900)\n",
    "\n",
    "sts_client = boto3.client('sts')\n",
    "boto3_session = boto3.session.Session()\n",
    "region_name = boto3_session.region_name\n",
    "bedrock_agent_client = boto3_session.client('bedrock-agent', region_name=region_name)\n",
    "service = 'aoss'\n",
    "s3_client = boto3.client('s3')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "s3_suffix = f\"{region_name}-{account_id}\"\n",
    "bucket_name = 'btr-data-1' # replace it with your bucket name.\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "bucket_name = 'btr-data-1' # replace it with your bucket name.\n",
    "# Check if bucket exists, and if not create S3 bucket for knowledge base data source\n",
    "try:\n",
    "    s3_client.head_bucket(Bucket=bucket_name)\n",
    "    print(f'Bucket {bucket_name} Exists')\n",
    "except ClientError as e:\n",
    "    print(f'Creating bucket {bucket_name}')\n",
    "    s3bucket = s3_client.create_bucket(\n",
    "        Bucket=bucket_name,\n",
    "        CreateBucketConfiguration={ 'LocationConstraint': region_name }\n",
    "    )\n",
    "import boto3\n",
    "import time\n",
    "vector_store_name = f'bedrock-sample-rag-{suffix}'\n",
    "index_name = f\"bedrock-sample-rag-index-{suffix}\"\n",
    "aoss_client = boto3_session.client('opensearchserverless')\n",
    "bedrock_kb_execution_role = create_bedrock_execution_role(bucket_name='btr-data-1')\n",
    "bedrock_kb_execution_role_arn = bedrock_kb_execution_role['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create security, network and data access policies within OSS\n",
    "encryption_policy, network_policy, access_policy = create_policies_in_oss(vector_store_name=vector_store_name,\n",
    "                       aoss_client=aoss_client,\n",
    "                       bedrock_kb_execution_role_arn=bedrock_kb_execution_role_arn)\n",
    "collection = aoss_client.create_collection(name=vector_store_name,type='VECTORSEARCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the OpenSearch serverless collection URL\n",
    "collection_id = collection['createCollectionDetail']['id']\n",
    "host = collection_id + '.' + region_name + '.aoss.amazonaws.com'\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for collection creation\n",
    "# This can take couple of minutes to finish\n",
    "response = aoss_client.batch_get_collection(names=[vector_store_name])\n",
    "# Periodically check collection status\n",
    "while (response['collectionDetails'][0]['status']) == 'CREATING':\n",
    "    print('Creating collection...')\n",
    "    interactive_sleep(5)\n",
    "    response = aoss_client.batch_get_collection(names=[vector_store_name])\n",
    "print('\\nCollection successfully created:')\n",
    "pp.pprint(response[\"collectionDetails\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create opensearch serverless access policy and attach it to Bedrock execution role\n",
    "try:\n",
    "    create_oss_policy_attach_bedrock_execution_role(collection_id=collection_id,\n",
    "                                                    bedrock_kb_execution_role=bedrock_kb_execution_role)\n",
    "    # It can take up to a minute for data access rules to be enforced\n",
    "    interactive_sleep(60)\n",
    "except Exception as e:\n",
    "    print(\"Policy already exists\")\n",
    "    pp.pprint(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector index in Opensearch serverless, with the knn_vector field index mapping, specifying the dimension size, name and engine.\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth, RequestError\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = auth = AWSV4SignerAuth(credentials, region_name, service)\n",
    "\n",
    "index_name = f\"bedrock-sample-index-{suffix}\"\n",
    "body_json = {\n",
    "   \"settings\": {\n",
    "      \"index.knn\": \"true\",\n",
    "       \"number_of_shards\": 1,\n",
    "       \"knn.algo_param.ef_search\": 512,\n",
    "       \"number_of_replicas\": 0,\n",
    "   },\n",
    "   \"mappings\": {\n",
    "      \"properties\": {\n",
    "         \"vector\": {\n",
    "            \"type\": \"knn_vector\",\n",
    "            \"dimension\": 1536,\n",
    "             \"method\": {\n",
    "                 \"name\": \"hnsw\",\n",
    "                 \"engine\": \"faiss\",\n",
    "                 \"space_type\": \"l2\"\n",
    "             },\n",
    "         },\n",
    "         \"text\": {\n",
    "            \"type\": \"text\"\n",
    "         },\n",
    "         \"text-metadata\": {\n",
    "            \"type\": \"text\"         }\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "# Build the OpenSearch client\n",
    "oss_client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index\n",
    "try:\n",
    "    response = oss_client.indices.create(index=index_name, body=json.dumps(body_json))\n",
    "    print('\\nCreating index:')\n",
    "    pp.pprint(response)\n",
    "\n",
    "    # index creation can take up to a minute\n",
    "    interactive_sleep(60)\n",
    "except RequestError as e:\n",
    "    # you can delete the index if its already exists\n",
    "    # oss_client.indices.delete(index=index_name)\n",
    "    print(f'Error while trying to create the index, with error {e.error}\\nyou may unmark the delete above to delete, and recreate the index')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearchServerlessConfiguration = {\n",
    "            \"collectionArn\": collection[\"createCollectionDetail\"]['arn'],\n",
    "            \"vectorIndexName\": index_name,\n",
    "            \"fieldMapping\": {\n",
    "                \"vectorField\": \"vector\",\n",
    "                \"textField\": \"text\",\n",
    "                \"metadataField\": \"text-metadata\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Ingest strategy - How to ingest data from the data source\n",
    "chunkingStrategyConfiguration = {\n",
    "    \"chunkingStrategy\": \"FIXED_SIZE\",\n",
    "    \"fixedSizeChunkingConfiguration\": {\n",
    "        \"maxTokens\": 512,\n",
    "        \"overlapPercentage\": 20\n",
    "    }\n",
    "}\n",
    "\n",
    "# The data source to ingest documents from, into the OpenSearch serverless knowledge base index\n",
    "s3Configuration = {\n",
    "    \"bucketArn\": f\"arn:aws:s3:::{bucket_name}\",\n",
    "    # \"inclusionPrefixes\":[\"*.*\"] # you can use this if you want to create a KB using data within s3 prefixes.\n",
    "}\n",
    "\n",
    "# The embedding model used by Bedrock to embed ingested documents, and realtime prompts\n",
    "embeddingModelArn = f\"arn:aws:bedrock:{region_name}::foundation-model/amazon.titan-embed-text-v1\"\n",
    "\n",
    "name = f\"bedrock-sample-knowledge-base-{suffix}\"\n",
    "description = \"RAG\"\n",
    "roleArn = bedrock_kb_execution_role_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KnowledgeBase\n",
    "from retrying import retry\n",
    "\n",
    "@retry(wait_random_min=1000, wait_random_max=2000,stop_max_attempt_number=7)\n",
    "def create_knowledge_base_func():\n",
    "    create_kb_response = bedrock_agent_client.create_knowledge_base(\n",
    "        name = name,\n",
    "        description = description,\n",
    "        roleArn = roleArn,\n",
    "        knowledgeBaseConfiguration = {\n",
    "            \"type\": \"VECTOR\",\n",
    "            \"vectorKnowledgeBaseConfiguration\": {\n",
    "                \"embeddingModelArn\": embeddingModelArn\n",
    "            }\n",
    "        },\n",
    "        storageConfiguration = {\n",
    "            \"type\": \"OPENSEARCH_SERVERLESS\",\n",
    "            \"opensearchServerlessConfiguration\":opensearchServerlessConfiguration\n",
    "        }\n",
    "    )\n",
    "    return create_kb_response[\"knowledgeBase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    kb = create_knowledge_base_func()\n",
    "except Exception as err:\n",
    "    print(f\"{err=}, {type(err)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get KnowledgeBase \n",
    "get_kb_response = bedrock_agent_client.get_knowledge_base(knowledgeBaseId = kb['knowledgeBaseId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataSource in KnowledgeBase \n",
    "create_ds_response = bedrock_agent_client.create_data_source(\n",
    "    name = name,\n",
    "    description = description,\n",
    "    knowledgeBaseId = kb['knowledgeBaseId'],\n",
    "    dataSourceConfiguration = {\n",
    "        \"type\": \"S3\",\n",
    "        \"s3Configuration\":s3Configuration\n",
    "    },\n",
    "    vectorIngestionConfiguration = {\n",
    "        \"chunkingConfiguration\": chunkingStrategyConfiguration\n",
    "    }\n",
    ")\n",
    "ds = create_ds_response[\"dataSource\"]\n",
    "pp.pprint(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataSource \n",
    "bedrock_agent_client.get_data_source(knowledgeBaseId = kb['knowledgeBaseId'], dataSourceId = ds[\"dataSourceId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start an ingestion job\n",
    "start_job_response = bedrock_agent_client.start_ingestion_job(knowledgeBaseId = kb['knowledgeBaseId'], dataSourceId = ds[\"dataSourceId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = start_job_response[\"ingestionJob\"]\n",
    "pp.pprint(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get job \n",
    "while(job['status']!='COMPLETE' ):\n",
    "  get_job_response = bedrock_agent_client.get_ingestion_job(\n",
    "      knowledgeBaseId = kb['knowledgeBaseId'],\n",
    "        dataSourceId = ds[\"dataSourceId\"],\n",
    "        ingestionJobId = job[\"ingestionJobId\"]\n",
    "  )\n",
    "  job = get_job_response[\"ingestionJob\"]\n",
    "pp.pprint(job)\n",
    "interactive_sleep(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the knowledge base Id in bedrock, that corresponds to the Opensearch index in the collection we created before, we will use it for the invocation later\n",
    "kb_id = kb[\"knowledgeBaseId\"]\n",
    "pp.pprint(kb_id)\n",
    "\n",
    "# Keep the kb_id for invocation later in the invoke request\n",
    "%store kb_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out KB using RetrieveAndGenerate API\n",
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", region_name=region_name)\n",
    "# Lets see how different Anthropic models responds to the input text we provide\n",
    "claude_model_ids = [ [\"Claude 3 Sonnet\", \"anthropic.claude-3-sonnet-20240229-v1:0\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_bedrock_llm_with_knowledge_base(query: str, model_arn: str, kb_id: str) -> str:\n",
    "    response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "        input={\n",
    "            'text': query\n",
    "        },\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            'type': 'KNOWLEDGE_BASE',\n",
    "            'knowledgeBaseConfiguration': {\n",
    "                'knowledgeBaseId': kb_id,\n",
    "                'modelArn': model_arn\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    generated_text = response['output']['text']\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = \"\"\"\n",
    "\n",
    "Human: Summarise the following content to 500 characters. The final output should only have 500 characters\n",
    "\n",
    "<context>\n",
    "{data_test}\n",
    "</context>\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "query2 = prompt2.format(data_test=df['ClusterText'][0])\n",
    "result2 = llm(query2).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"The following text contains desciption on an outbreak in the current_outbreak_tag. <current_outbreak>\" + result2 + \"</current_outbreak. Use the data extracted \\\n",
    "    on \" + df_final.name[0] + \" to understand whether the current_outbreak_tag outbreak is as bad as the outbreaks reported before\"\n",
    "\n",
    "for model_id in claude_model_ids:\n",
    "    model_arn = f'arn:aws:bedrock:{region_name}::foundation-model/{model_id[1]}'\n",
    "    generated_text = ask_bedrock_llm_with_knowledge_base(query, model_arn, kb_id)\n",
    "    \n",
    "    print(f\"Generated using Amazon Bedrock and {model_id[0]}:\")\n",
    "    pp.pprint(generated_text)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
